{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codebook_08_2022_Diverse_Misinformation_Survey.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "* Title: Diverse Misinformation: impacts of human biases on detection of deepfakes on online social networks\n",
        "* Cite as: Lovato et al. Diverse Misinformation: impacts of human biases on detection of deepfakes on online social networks (2022). \n",
        "* link to ArXiv pre-print [coming soon] \n",
        "* Contact: Juniper Lovato, University of Vermont, jlovato@uvm.edu \n",
        "* Authors and data collectors: Juniper Lovato1, Laurent H ÃÅebert-Dufresne1,2, Jonathan St-Onge1, Randall Harp1,3, , Gabriela Salazar Lopez1, Ijaz Ul Haq1, Sean Rogers1, AnneMarie Stupinski1, and Jeremiah Onaolapo. 1Vermont Complex Systems Center, University of Vermont, Burlington, 05405, USA2Department of Computer Science, University of Vermont, Burlington, 05405, USA3Department of Philosophy, University of Vermont, Burlington, 05405, USA\n",
        "* Data is a survey panel of US social media users, survey is conducted in English. \n",
        "* Keywords: Diversity, Privacy, Security, Social Media Behavior \n",
        "* 2022 at the University of Vermont \n",
        "* IRB CHRBSS (Behavioral) STUDY00001786 Approved 12/6/2022"
      ],
      "metadata": {
        "id": "X_Kw5TjLKlrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Original Data Description "
      ],
      "metadata": {
        "id": "HIZ-NzlW173G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA FILE LOCATION: University of Vermont - not currently available under IRB \n",
        "TYPE: Convenience Sample Survey\n",
        "SIZE: N=1,100 survey participants \n",
        "\n",
        "DESCRIPTIVE ABSTRACT: Online social media users are not all equally susceptible to misinformation; their level of susceptibility depends on their biases. The interplay between an observer's biases and the diverse forms of misinformation they encounter is what we call in this paper `diverse misinformation'. Our paper explores deepfakes as a type of misinformation as a means to investigate how U.S. social media users' biases generally impact susceptibility to misinformation online. We choose deepfakes as a case study of the impacts of diverse misinformation for two reasons: 1.) their status of being misinformation is binary; they either are a deepfake or are not; 2.) deepfakes are a current real-world concern with associated harms that need to be better understood. \n",
        "\n",
        "SOURCE OF SURVEY PANEL: \n",
        "Qualtrics \n",
        "\n",
        "INFO:\n",
        "comma characters are used to separate variables in the csv data file. \n",
        "memory usage: 1.1+ MB\n",
        "Int64Index: 1866 entries (No. Videos watched) \n",
        "Data columns (total 70 columns):\n"
      ],
      "metadata": {
        "id": "Emb6PVW38IBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2foHNLyKWi9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Secondary Data Description "
      ],
      "metadata": {
        "id": "Nmxp5yasMstl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Secondary Data\n",
        "\n",
        "* Source: Dolhansky, B., Howes, R., Pflaum, B., Baram, N. & Ferrer, C. The deepfake detection challenge (dfdc) preview dataset(2019). 1910.08854. Openly accessile. \n",
        "*   Summary: For this project we use the publicly available Facebook AI Research Deepfake Detection Challenge (DFDC) preview data set (N = 5,000 video clips). The video clips provided may be deepfake or real. Additionally, the video clips provided may have been purposefully altered through several means, see list of augmenters and Distractors below. A video's deepfake status (deepfake or not) will not be revealed to the respondent during or after such a survey. Many augmenters and distractors will be noticeable to the respondent, but they shall not be specifically revealed.\n",
        "\n",
        "*   RangeIndex: 5000 entries, 0 to 4999\n",
        "*   Data columns (total 28 columns):\n",
        "*   dtypes: int64(1), object(27)\n",
        "*   memory usage: 1.1+ MB"
      ],
      "metadata": {
        "id": "e9mg732UMwL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Book for Primary Data"
      ],
      "metadata": {
        "id": "YgEXur7n2Cll"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Column ,N,Dtype,Description\n",
        "*   is_fake,941,Binary ,Is a deepfake video\n",
        "*   is_not_fake,925,Binary ,Is not a deepfake video\n",
        "*   Gaze_to_ord_scale,6115,Scale,Likert scale from unpleasant to pleasant - Video's Gaze\n",
        "*   Facial_expression_to_ord_scale,6114,Scale,Likert scale from unpleasant to   pleasant - Video's facial expression\n",
        "*   Pose_to_ord_scale,6083,Scale,Likert scale from unpleasant to pleasant - *   Video's pose\n",
        "*   Personality_to_ord_scale,6240,Scale,Likert scale from unpleasant to pleasant - Video's Personality\n",
        "*   Hair_to_ord_scale,6340,Scale,Likert scale from unpleasant to pleasant - Video's Hair\n",
        "*   Style_to_ord_scale,6211,Scale,Likert scale from unpleasant to pleasant - Video's Style\n",
        "*   Age_to_ord_scale,6529,Scale,Likert scale from unpleasant to pleasant - Video's Age\n",
        "*   Background_environment_to_ord_scale,5931,Scale,Likert scale from unpleasant to pleasant - Video's Background Environment\n",
        "*   Behavior_to_ord_scale,6213,Scale,Likert scale from unpleasant to pleasant - Video's Behavior\n",
        "*   Movement_to_ord_scale,5994,Scale,Likert scale from unpleasant to pleasant - Video's Movement\n",
        "*   voice_to_ord_scale,6216,Scale,Likert scale from unpleasant to pleasant - Video's Voice\n",
        "*   tone_to_ord_scale,6174,Scale,Likert scale from unpleasant to pleasant - Video's Tone\n",
        "*   Part_education_level_to_ord_scale,8510,Scale,Education Levels of Participant\n",
        "income_to_ord_scale,4668,Scale,Income Levels of Participant\n",
        "*   part_social_media_use_to_ord_scale,12494,Scale,How often the participant uses social media \n",
        "*   part_knowledge_deepfake_to_ord_scale,3152,Scale,How much the participant knows about deepfakes\n",
        "*   Part_Primed_to_nom,302,Binary ,Did the participant knew the survey was about deepfakes before taking it\n",
        "*   Part_Guessed_Vid_Real_to_nom,1371,Binary ,Participant guess the video was real \n",
        "*   Part_NOT_Primed_to_nom,1564,Binary ,Did the participant didn't know the survey was about deepfakes before taking it\n",
        "*   Part_Guessed_Vid_Fake_to_nom,495,Binary ,Participant guess the video was fake \n",
        "*   Part_Gender_Men,1028,Binary ,Participant was male (non-binary options were included by N was too small so we dropped the column) \n",
        "*   Part_Gender_Woman,838,Binary ,Participant was female  v\n",
        "*   Part_Age_18_29,302,Binary ,Participant is in the age group 18-29\n",
        "*   Part_Age_30_49,498,Binary ,Participant is in the age group 30-49\n",
        "*   Part_Age_50_64,554,Binary ,Participant is in the age group 50-64\n",
        "*   Part_Age_65plus,512,Binary ,Participant is in the age group over 65\n",
        "*   part_region_Middle_Atlantic,278,Binary ,Participant lives in the middle atlantic  USregion\n",
        "*   part_region_Midwest,396,Binary ,Participant lives in the midwest US region\n",
        "*   part_region_South,508,Binary ,Participant lives in the southen US region\n",
        "*   part_region_Southwest,266,Binary ,Participant lives in the southwest US region\n",
        "*   part_region_newengland,84,Binary ,Participant lives in the newengland US region\n",
        "*   part_region_west,308,Binary ,Participant lives in the west US region\n",
        "*   Gender_Guess_Men,760,Binary ,Participant guessed the video person(a) was male (non-binary options were included by N was too small so we dropped the column) \n",
        "*   Gender_Guess_Women,1022,Binary ,Participant guessed the video person(a) was female (non-binary options were included by N was too small so we dropped the column) \n",
        "*   age_guess_18_29,561,Binary ,Participant guessed that the video person(a) is in the age group 18-29\n",
        "*   age_guess_30_49,940,Binary ,Participant guessed that the video person(a)  is in the age group 30-49\n",
        "*   age_guess_50_64,312,Binary ,Participant guessed that the video person(a)  is in the age group 50-64\n",
        "*   age_guess_65plus,44,Binary ,Participant guessed that the video person(a)  is in the age group over 65\n",
        "*   part_race_POC,380,Binary ,Participant identifies as a person of color (POC)\n",
        "*   part_race_White,1228,Binary ,Participant identifies as white \n",
        "*   POC_Guess_No,933,Binary ,Participant guessed that the video person(a) is not a person of color (POC)\n",
        "*   POC_Guess_yes,874,Binary ,Participant guessed that the video person(a) is a person of color (POC)\n",
        "*   Real_Guess_Real,694,Binary ,Participant guessed the video is real and the video is indeed real\n",
        "*   Fake_Guess_Real,677,Binary ,Participant guessed the video is fake and the video is actually real\n",
        "*   Real_Guess_Fake,231,Binary ,Participant guessed the video is real and the video is actually fake\n",
        "*   Fake_Guess_Fake,264,Binary ,Participant guessed the video is fake and the video is indeed fake\n",
        "*   Part_Woman_POC,1092,Binary ,Participant identifies as a female and a person of color\n",
        "*   Part_Male_POC,774,Binary ,Participant identifies as a male and a person of color\n",
        "*   Part_Woman_White,708,Binary ,Participant identifies as a female and white\n",
        "*   Part_Male_White,1158,Binary ,Participant identifies as a male and white\n",
        "*   Woman_POC,900,Binary ,Participant identifies as a female and a person of color\n",
        "*   Woman_White,975,Binary ,Participant identifies as a female and white\n",
        "*   Male_POC_Match,383,Binary ,Participant identifies as a male person of color and identified the video person(a) as also being a male person of color\n",
        "*   Woman_POC_Match,515,Binary ,Participant identifies as a female person of color and identified the video person(a) as also being a female person of color\n",
        "*   Woman_White_Match,357,Binary ,Participant identifies as a white female and identified the video person(a) as also being a white female \n",
        "*   Male_White_Match,544,Binary ,Participant identifies as a white male and identified the video person(a) as also being a white male \n",
        "*   age_1829_Match,142,Binary ,Participant is age 18-29 and identified the video person(a) as also being age 18-29\n",
        "*   age_3049_Match,307,Binary ,Participant is age 30-49 and identified the video person(a) as also being age 30-49\n",
        "*   age_5064_Match,102,Binary ,Participant is age 50-64 and identified the video person(a) as also being age 50-64\n",
        "*   age_over65_Match,23,Binary ,Participant is age over 65 and identified the video person(a) as also being age over 65\n",
        "*   Male_POC_MisMatch,587,Binary ,Participant identifies as a male person of color and identified the video person(a) as not being a male person of color\n",
        "*   Woman_POC_MisMatch,385,Binary ,Participant identifies as a female person of color and identified the video person(a) as not being a female person of color\n",
        "*   Woman_White_MisMatch,618,Binary ,Participant identifies as a white female and identified the video person(a) as not being a white female \n",
        "*   Male_White_MisMatch,363,Binary ,Participant identifies as a white male and identified the video person(a) as not being a white male \n",
        "*   age_1829_MisMatch,419,Binary ,Participant is age 18-29 and identified the video person(a) as not being age 18-29\n",
        "*   age_3049_MisMatch,633,Binary ,Participant is age 30-49 and identified the video person(a) as not being age 30-49\n",
        "*   age_5064_MisMatch,210,Binary ,Participant is age 50-64 and identified the video person(a) as not being age 50-64\n",
        "*   age_over65_MisMatch,21,Binary ,Participant is age over 65 and identified the video person(a) as not being age over 65\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8daAhf6_W7NI"
      }
    }
  ]
}